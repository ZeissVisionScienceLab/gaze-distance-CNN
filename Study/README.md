# Eye-tracking Study  


The study aims to collect eye tracking data during target fixation in Virtual Reality. Â 

The scenes were created to resemble natural environments as closely as possible, aiming for natural gaze behavior. Participants played a simple reaction time experiment while wearing a VR headset with a built-in eye tracker. The task is to look at a target object appearing subsequently at different positions and react to color changes as quickly as possible. Eye movements are recorded during target fixation.

This repository includes the study codebase. Due to the use of commercial assets, the VR scenes were not uploaded. Exemplary scenes are displayed below. The experiment contains an executable training scene which is representative for how the experiment can be set up.


<img src="https://github.com/AnnaLenavonBehren/EyetrackingStudy/blob/78d24798d7041dbe5ecc34861ef276ef7483809f/indoor_scene.png" alt="indoor scene" height="200"/> <img src="https://github.com/AnnaLenavonBehren/EyetrackingStudy/blob/78d24798d7041dbe5ecc34861ef276ef7483809f/outdoor_scene.png" alt="outdoor scene" height="200"/>
---

**Technical requirements:** 
Game Engine: Unity v2022.3.19f1 with C# 9.0   
VR HMD: HTC Vive Pro Eye and Vive SRanipal SDK v1.3.6.12  
User input: Xbox controller  



