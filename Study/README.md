# Eye-tracking Study  


The study aimed to collect eye-tracking data during target fixation in Virtual Reality.  

The scenes were created to resemble natural environments as closely as possible, aiming for natural gaze behavior. Participants played a simple reaction time experiment while wearing a VR headset with a built-in eye tracker. The task was to look at a target object appearing subsequently at different positions and react to color changes as quickly as possible. Eye movements were recorded during target fixation.

This repository includes the study codebase. Due to the use of commercial assets, the VR scenes were not uploaded. Exemplary scenes are displayed below:  


<img src="https://github.com/AnnaLenavonBehren/EyetrackingStudy/blob/78d24798d7041dbe5ecc34861ef276ef7483809f/indoor_scene.png" alt="indoor scene" height="200"/> <img src="https://github.com/AnnaLenavonBehren/EyetrackingStudy/blob/78d24798d7041dbe5ecc34861ef276ef7483809f/outdoor_scene.png" alt="outdoor scene" height="200"/>
---

**Technical requirements:** 
Game Engine: Unity v2022.3.19f1 with C# 9.0   
VR HMD: HTC Vive Pro Eye and Vive SRanipal SDK v1.3.6.12  
User input: Xbox controller  



